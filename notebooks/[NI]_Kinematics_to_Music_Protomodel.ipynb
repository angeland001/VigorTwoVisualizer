{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dakilaledesma/VIGOR2/blob/main/notebooks/%5BNI%5D_Kinematics_to_Music_Protomodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "XysEK55L30ix"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv8KgyGL-wtX",
        "outputId": "223ad682-2b37-48fd-a356-507669724343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  305M  100  305M    0     0  30.0M      0  0:00:10  0:00:10 --:--:-- 46.3M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 90.6M  100 90.6M    0     0  25.1M      0  0:00:03  0:00:03 --:--:-- 25.1M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  834M  100  834M    0     0  45.6M      0  0:00:18  0:00:18 --:--:-- 48.3M\n"
          ]
        }
      ],
      "source": [
        "! curl -L https://herbarium.ucht.cloud/s/AoZFbaKWofEfHiF/download --output motions.zip\n",
        "! curl -L https://herbarium.ucht.cloud/s/Cn55KNbEBqtrDCg/download --output mp3.zip\n",
        "! curl -L https://herbarium.ucht.cloud/s/MayD6rAGWoKmGw8/download --output keypoints3d.zip\n",
        "! unzip -q motions.zip\n",
        "! unzip -q keypoints3d.zip\n",
        "! unzip -q mp3.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_dict = {}\n",
        "motion_dict = {}"
      ],
      "metadata": {
        "id": "4IEfhm99BUSj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pYUyel4isa5S"
      },
      "outputs": [],
      "source": [
        "# Thanks to https://stackoverflow.com/questions/69387104/how-to-convert-wav-audio-file-from-mel-spectrogram\n",
        "import librosa\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "for aud in glob(\"mp3/*.mp3\"):\n",
        "  my_audio_as_np_array, my_sample_rate = librosa.load(aud)\n",
        "\n",
        "  spec = librosa.feature.melspectrogram(y=my_audio_as_np_array,\n",
        "                                          sr=my_sample_rate, \n",
        "                                              n_fft=2048, \n",
        "                                              hop_length=512, \n",
        "                                              win_length=None, \n",
        "                                              window='hann', \n",
        "                                              center=True, \n",
        "                                              pad_mode='reflect', \n",
        "                                              power=2.0,\n",
        "                                      n_mels=128)\n",
        "  spec = spec.T[:1272].T # Minimum is (128, 1273)\n",
        "  bn = os.path.basename(aud)\n",
        "  audio_dict[aud] = spec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for fn in glob(\"keypoints3d/*.pkl\"):\n",
        "  with open(fn, \"rb\") as motion:\n",
        "    m = pickle.load(motion)\n",
        "    bn = os.path.basename(fn)\n",
        "    motion_dict[bn] = m[\"keypoints3d\"][:425] # Minimum is (426, 17, 3), axis=0 is all different"
      ],
      "metadata": {
        "id": "fZn4k-IN-xps"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "input_img = keras.Input(shape=(426, 17, 3))\n",
        "\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "2xGOEVPdxQAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = librosa.feature.inverse.mel_to_audio(spec, \n",
        "                                           sr=my_sample_rate, \n",
        "                                           n_fft=2048, \n",
        "                                           hop_length=512, \n",
        "                                           win_length=None, \n",
        "                                           window='hann', \n",
        "                                           center=True, \n",
        "                                           pad_mode='reflect', \n",
        "                                           power=2.0, \n",
        "                                           n_iter=32)\n",
        "\n",
        "import soundfile as sf\n",
        "sf.write(\"test1.wav\", res, sashi_sr)"
      ],
      "metadata": {
        "id": "tT5bPm0aqwgy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHxlBbklG2pIJSh04qOfEZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}